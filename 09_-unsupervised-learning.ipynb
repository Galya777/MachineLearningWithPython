{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Обучение без учител - Unsupervised Learning\n",
    "Целите днес\n",
    "\n",
    "    Клъстеризация (Clustering):\n",
    "\n",
    "    Базирана на разстояние - kMeans\n",
    "    Агломеративна клъстеризация (Agglomerative clustering)\n",
    "    Базирана на плътност - DBScan\n",
    "    Оценка на клъстеризация\n",
    "\n",
    "    Намаляване на размерността (Dimensionality reduction)\n",
    "\n",
    "    PCA (Principal component analysis)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mglearn\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore sklearn's convergence warning \n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "1. Клъстеризация\n",
    "k-Means Clustering\n",
    "\n",
    "    Алгоритъм за обучение без учител (Unsupervised learning)\n",
    "    Разделя данните на k сходни групи, наречени клъстери\n",
    "\n",
    "Да се пробваме с make_blobs:\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(random_state=1)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1]);\n",
    "\n",
    "Така изглежда само X, където няма информация за категориите.\n",
    "\n",
    "X\n",
    "\n",
    "array([[-7.94152277e-01,  2.10495117e+00],\n",
    "       [-9.15155186e+00, -4.81286449e+00],\n",
    "       [-1.14418263e+01, -4.45781441e+00],\n",
    "       [-9.76761777e+00, -3.19133737e+00],\n",
    "       [-4.53655648e+00, -8.40186288e+00],\n",
    "       [-6.26302115e+00, -8.10666081e+00],\n",
    "       [-6.38481234e+00, -8.47302970e+00],\n",
    "       [-9.20490564e+00, -4.57687928e+00],\n",
    "       [-2.76017908e+00,  5.55121358e+00],\n",
    "       [-1.17104176e+00,  4.33091816e+00],\n",
    "       [-1.00364080e+01, -5.56912090e+00],\n",
    "       [-9.87589123e+00, -2.82386464e+00],\n",
    "       [-7.17532921e+00, -8.77059017e+00],\n",
    "       [-2.40671820e+00,  6.09894447e+00],\n",
    "       [-4.87418245e+00, -1.00495890e+01],\n",
    "       [-6.07854700e+00, -7.93969420e+00],\n",
    "       [-6.83238762e+00, -7.47067670e+00],\n",
    "       [-2.34673261e+00,  3.56128423e+00],\n",
    "       [-1.03415662e+01, -3.90975169e+00],\n",
    "       [-1.10926243e+01, -3.78396611e+00],\n",
    "       [-6.50212109e+00, -7.91249101e+00],\n",
    "       [-1.02639310e+01, -3.92073400e+00],\n",
    "       [-6.81608302e+00, -8.44986926e+00],\n",
    "       [-1.34052081e+00,  4.15711949e+00],\n",
    "       [-1.03729975e+01, -4.59207895e+00],\n",
    "       [-7.37499896e+00, -1.05880659e+01],\n",
    "       [-6.62351774e+00, -8.25338334e+00],\n",
    "       [-1.35938959e+00,  4.05424002e+00],\n",
    "       [-1.97451969e-01,  2.34634916e+00],\n",
    "       [-6.54430585e+00, -9.29756949e+00],\n",
    "       [-1.92744799e+00,  4.93684534e+00],\n",
    "       [-2.80207810e+00,  4.05714715e+00],\n",
    "       [-7.58197664e+00, -9.15025493e+00],\n",
    "       [-1.85139546e+00,  3.51886090e+00],\n",
    "       [-8.37006175e+00, -3.61533685e+00],\n",
    "       [-7.25145196e+00, -8.25497398e+00],\n",
    "       [-8.79879462e+00, -3.76819213e+00],\n",
    "       [-1.13708298e+01, -3.63818916e+00],\n",
    "       [-1.01786328e+01, -4.55726918e+00],\n",
    "       [-7.20132693e+00, -8.27228229e+00],\n",
    "       [-6.78421711e+00, -8.22634081e+00],\n",
    "       [-9.64716652e+00, -5.26563196e+00],\n",
    "       [-1.98197711e+00,  4.02243551e+00],\n",
    "       [-1.12277706e+01, -3.40281105e+00],\n",
    "       [-9.79941278e+00, -3.83433990e+00],\n",
    "       [-6.53541686e+00, -8.01552689e+00],\n",
    "       [-7.57969185e-01,  4.90898421e+00],\n",
    "       [ 5.26015501e-01,  3.00999353e+00],\n",
    "       [-2.77687025e+00,  4.64090557e+00],\n",
    "       [-1.78245013e+00,  3.47072043e+00],\n",
    "       [-1.02200406e+01, -4.15410662e+00],\n",
    "       [-6.40583239e+00, -9.78066645e+00],\n",
    "       [-6.98706106e+00, -7.53484784e+00],\n",
    "       [-7.46576038e+00, -7.32922249e+00],\n",
    "       [-1.53940095e+00,  5.02369298e+00],\n",
    "       [-6.56967086e+00, -8.32793126e+00],\n",
    "       [-1.06177133e+01, -3.25531651e+00],\n",
    "       [-8.72395657e+00, -1.98624680e+00],\n",
    "       [-1.61734616e+00,  4.98930508e+00],\n",
    "       [-1.14663009e+00,  4.10839703e+00],\n",
    "       [-9.81115111e+00, -3.54329690e+00],\n",
    "       [-7.71179887e+00, -7.25174121e+00],\n",
    "       [-6.56169737e+00, -6.86000222e+00],\n",
    "       [-1.00223295e+01, -4.72851017e+00],\n",
    "       [-1.18556944e+01, -2.71718452e+00],\n",
    "       [-5.73342507e+00, -8.44053597e+00],\n",
    "       [-2.41395785e+00,  5.65935802e+00],\n",
    "       [-8.33744094e+00, -7.83968038e+00],\n",
    "       [-1.83198811e+00,  3.52863145e+00],\n",
    "       [-9.57421815e+00, -3.87600848e+00],\n",
    "       [-9.59422086e+00, -3.35977002e+00],\n",
    "       [-9.25715605e+00, -4.90704915e+00],\n",
    "       [-6.46256290e+00, -7.73294590e+00],\n",
    "       [-8.20576492e-01,  5.33759195e+00],\n",
    "       [ 2.42271161e-04,  5.14853403e+00],\n",
    "       [-9.68207756e+00, -5.97554976e+00],\n",
    "       [-6.19599603e+00, -7.40281646e+00],\n",
    "       [-7.02121319e+00, -8.37954235e+00],\n",
    "       [-2.18773166e+00,  3.33352125e+00],\n",
    "       [-1.04448411e+01, -2.72884084e+00],\n",
    "       [-5.27930518e-01,  5.92630669e+00],\n",
    "       [-1.11969805e+01, -3.09000323e+00],\n",
    "       [-9.83767543e+00, -3.07717963e+00],\n",
    "       [-5.16022348e+00, -7.04217141e+00],\n",
    "       [-2.35122066e+00,  4.00973634e+00],\n",
    "       [-5.25790464e-01,  3.30659860e+00],\n",
    "       [-1.46864442e+00,  6.50674501e+00],\n",
    "       [-7.58703957e-01,  3.72276201e+00],\n",
    "       [-1.03039165e+01, -3.12537390e+00],\n",
    "       [-2.33080604e+00,  4.39382527e+00],\n",
    "       [-5.90454361e+00, -7.78373539e+00],\n",
    "       [-1.60875215e+00,  3.76949422e+00],\n",
    "       [-1.86845414e+00,  4.99311306e+00],\n",
    "       [-1.06683748e+01, -3.57578476e+00],\n",
    "       [-8.87629480e+00, -3.54444801e+00],\n",
    "       [-6.02605758e+00, -5.96624846e+00],\n",
    "       [-7.04747278e+00, -9.27524683e+00],\n",
    "       [-1.37397258e+00,  5.29163103e+00],\n",
    "       [-6.25393051e+00, -7.10878601e+00],\n",
    "       [ 8.52518583e-02,  3.64528297e+00]])\n",
    "\n",
    "Ще се опитаме да открием нещо такова с k-Means clustering:\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y);\n",
    "\n",
    "Кодът би трябвало да изглежда съвсем познато, освен че fit не приeма аргумент y:\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=2)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "Да начертаем резултатите:\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y_pred);\n",
    "\n",
    "Изглежда сме намерили същите клъстери. Това значи ли, че y == y_pred?\n",
    "\n",
    "y == y_pred\n",
    "\n",
    "array([False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False])\n",
    "\n",
    "print(y)\n",
    "print(y_pred)\n",
    "\n",
    "[0 1 1 1 2 2 2 1 0 0 1 1 2 0 2 2 2 0 1 1 2 1 2 0 1 2 2 0 0 2 0 0 2 0 1 2 1\n",
    " 1 1 2 2 1 0 1 1 2 0 0 0 0 1 2 2 2 0 2 1 1 0 0 1 2 2 1 1 2 0 2 0 1 1 1 2 0\n",
    " 0 1 2 2 0 1 0 1 1 2 0 0 0 0 1 0 2 0 0 1 1 2 2 0 2 0]\n",
    "[1 2 2 2 0 0 0 2 1 1 2 2 0 1 0 0 0 1 2 2 0 2 0 1 2 0 0 1 1 0 1 1 0 1 2 0 2\n",
    " 2 2 0 0 2 1 2 2 0 1 1 1 1 2 0 0 0 1 0 2 2 1 1 2 0 0 2 2 0 1 0 1 2 2 2 0 1\n",
    " 1 2 0 0 1 2 1 2 2 0 1 1 1 1 2 1 0 1 1 2 2 0 0 1 0 1]\n",
    "\n",
    "y и y_pred създават идентични разделения на данните, но номерацията им е различна.\n",
    "\n",
    "В sklearn има метрика, която хваща това:\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "adjusted_rand_score(y, y_pred)\n",
    "\n",
    "1.0\n",
    "\n",
    "adjusted_rand_score има повече особености, но ще ги погледнем по-натам.\n",
    "\n",
    "Как работи k-Means Clustering:\n",
    "\n",
    "    Алгоритъма избира \n",
    "\n",
    "    произволни точки, наречени \"центрове\".\n",
    "    Всяка точка от данните се присъединява към клъстера на най-близкия център.\n",
    "    След като всички точки се присъединят към даден клъстер, се преизчислява центъра на клъстерите.\n",
    "    Стъпки 2-4 се повтарят докато не се получи стабилна позиция.\n",
    "\n",
    "mglearn.plots.plot_kmeans_algorithm()\n",
    "\n",
    "k-Means открива три центъра и класифицира всяка точка като член на клъстeра на най-близкия център.\n",
    "\n",
    "kmeans.cluster_centers_\n",
    "\n",
    "array([[ -6.58196786,  -8.17239339],\n",
    "       [ -1.4710815 ,   4.33721882],\n",
    "       [-10.04935243,  -3.85954095]])\n",
    "\n",
    "mglearn.plots.plot_kmeans_boundaries()\n",
    "\n",
    "Един от параметрите на KMeans е колко клъстера да намери алгоритъма. Обърнете внимание, че той не знае колко клъстера има в данните.\n",
    "\n",
    "Това е възможен отговор за k=2:\n",
    "\n",
    "assignments = KMeans(n_clusters=2, random_state=0).fit_predict(X)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignments);\n",
    "\n",
    "Това е възможен отговор за k=5:\n",
    "\n",
    "assignments = KMeans(n_clusters=5, random_state=0).fit_predict(X)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignments);\n",
    "\n",
    "Избор на оптимален параметър k\n",
    "\n",
    "Избор на оптимален параметър\n",
    "\n",
    "може да бъде направен чрез \"метода на лакътя\" - Еlbow method. Методът гласи, че:\n",
    "\n",
    "    Броят клъстери трябда да бъде избран така, че добавянето на нов клъстер да не дава много по-добро моделиране на данните.\n",
    "\n",
    "Колко добре са модерирани данните може да се измери например чрез сумата от разстоянията (на квадрат) от примерите до центровете на клъстерите, към които принадлежат. Тази информация се намира в атрибутът inertia_ на обученият kMeans алгоритъм.\n",
    "\n",
    "Повече за методът можете да прочетете в страницата в Уикипедия).\n",
    "\n",
    "# Elbow method\n",
    "K = range(1,10)\n",
    "SSE = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(X)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(K,SSE,'bx-')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('cluster numbers')\n",
    "plt.show()\n",
    "\n",
    "Един от проблемите на k-Means е, че не може да се справи със всякаква форма на клъстерите. Например:\n",
    "\n",
    "X_varied, y_varied = make_blobs(n_samples=200, cluster_std=[1.0, 2.5, 0.5], random_state=170)\n",
    "y_pred = KMeans(n_clusters=3, random_state=0).fit_predict(X_varied)\n",
    "mglearn.discrete_scatter(X_varied[:, 0], X_varied[:, 1], y_pred);\n",
    "\n",
    "Вероятно по-добро разделение щеше да бъде гъстите региони бяха два от клъстерите и всичко между тях беше третия.\n",
    "\n",
    "Ето и друг пример:\n",
    "\n",
    "X, y = make_blobs(random_state=170, n_samples=600)\n",
    "random = np.random.RandomState(74)\n",
    "transformation = random.normal(size=(2, 2))\n",
    "X = np.dot(X, transformation)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1]);\n",
    "\n",
    "Тук ясно се виждат три отделни клъстера. Но какво ли ще намери k-Means?\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=mglearn.cm3)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='^', c='orange', s=200, linewidth=2);\n",
    "\n",
    "Друго, с което k-Means няма да се справи добре е make_moons:\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "plt.scatter(X[:, 0], X[:, 1]);\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=mglearn.cm2, s=60)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='^', c='orange', s=100, linewidth=2);\n",
    "\n",
    "Agglomerative Clustering\n",
    "\n",
    "Как работи:\n",
    "\n",
    "    Декларира всяка точка в отделен клъстър\n",
    "    Събира двата най-близки клъстера в един\n",
    "    Повтаря стъпка две докато не останат \n",
    "\n",
    "    клъстера\n",
    "\n",
    "Какво значи \"най-близки\" клъстери се контролира от параметри.\n",
    "\n",
    "Повече детайли в документацията.\n",
    "\n",
    "mglearn.plots.plot_agglomerative_algorithm()\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X, y = make_blobs(random_state=1)\n",
    "clustering = AgglomerativeClustering(n_clusters=3)\n",
    "assignment = clustering.fit_predict(X)\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignment);\n",
    "\n",
    "Този алгоритъм също не се оправя добре с make_moons:\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=2)\n",
    "assignment = clustering.fit_predict(X)\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignment);\n",
    "\n",
    "Поради начина си на работа, AgglomerativeClustering няма predict – той не може да генерализира за нови точки. Има само fit и fit_predict.\n",
    "DBSCAN\n",
    "\n",
    "    Идва от \"Density-Based Spatial Clustering of Applications with Noise\"\n",
    "    Шокиращо, нали?\n",
    "    Няма нужда да му давате брой клъстери\n",
    "    Определя някои точки като шум и не ги начислява в клъстър\n",
    "    Може да открива всякакви форми\n",
    "    По-бавен\n",
    "\n",
    "Как работи?\n",
    "\n",
    "    Причислява точките в три категории – вътрешни примери (\"core sample\"), точки по околността (\"boundary points\") и шум (\"noise\").\n",
    "    Два основни параметъра – eps и min_samples.\n",
    "    Гранични точки са точки, които са на eps разстоянието от вътрешните (core samples), но не са core samples.\n",
    "    Шум е всичко останало.\n",
    "\n",
    "Повече детайли в документацията.\n",
    "\n",
    "mglearn.plots.plot_dbscan()\n",
    "\n",
    "min_samples: 2 eps: 1.000000  cluster: [-1  0  0 -1  0 -1  1  1  0  1 -1 -1]\n",
    "min_samples: 2 eps: 1.500000  cluster: [0 1 1 1 1 0 2 2 1 2 2 0]\n",
    "min_samples: 2 eps: 2.000000  cluster: [0 1 1 1 1 0 0 0 1 0 0 0]\n",
    "min_samples: 2 eps: 3.000000  cluster: [0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "min_samples: 3 eps: 1.000000  cluster: [-1  0  0 -1  0 -1  1  1  0  1 -1 -1]\n",
    "min_samples: 3 eps: 1.500000  cluster: [0 1 1 1 1 0 2 2 1 2 2 0]\n",
    "min_samples: 3 eps: 2.000000  cluster: [0 1 1 1 1 0 0 0 1 0 0 0]\n",
    "min_samples: 3 eps: 3.000000  cluster: [0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "min_samples: 5 eps: 1.000000  cluster: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
    "min_samples: 5 eps: 1.500000  cluster: [-1  0  0  0  0 -1 -1 -1  0 -1 -1 -1]\n",
    "min_samples: 5 eps: 2.000000  cluster: [-1  0  0  0  0 -1 -1 -1  0 -1 -1 -1]\n",
    "min_samples: 5 eps: 3.000000  cluster: [0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "\n",
    "DBSCAN вече може да се справи с make_moons:\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, s=60);\n",
    "\n",
    "С подходящия eps, DBSCAN може да се справи и онези странни три клъстера от по-рано:\n",
    "\n",
    "X, y = make_blobs(random_state=170, n_samples=600)\n",
    "random = np.random.RandomState(74)\n",
    "transformation = random.normal(size=(2, 2))\n",
    "X = np.dot(X, transformation)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.20)\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, s=60);\n",
    "\n",
    "Обърнете внимание, че подобно на AgglomerativeClustering, DBSCAN има само fit_predict.\n",
    "Оценяване на клъстеризация\n",
    "\n",
    "Погледнахме за момент adjusted_rand_score. Нека видим какво прави:\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "Ще пробваме пак с make_moons:\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1]);\n",
    "\n",
    "Ще видим оценката на тези три алгоритъма:\n",
    "\n",
    "algorithms = [KMeans(n_clusters=2), AgglomerativeClustering(n_clusters=2), DBSCAN()]\n",
    "\n",
    "Ще генерираме random_clusters, който раздава произволен клъстeр на всяка точка:\n",
    "\n",
    "random_state = np.random.RandomState(seed=0)\n",
    "random_clusters = random_state.randint(low=0, high=2, size=len(X))\n",
    "random_clusters\n",
    "\n",
    "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
    "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
    "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
    "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
    "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
    "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
    "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
    "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
    "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
    "       0, 0])\n",
    "\n",
    "И да начертаем диаграма:\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 3), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters, cmap=mglearn.cm3, s=60)\n",
    "axes[0].set_title(\"Random assignment - ARI: {:.2f}\".format(adjusted_rand_score(y, random_clusters)))\n",
    "\n",
    "for ax, algorithm in zip(axes[1:], algorithms):\n",
    "    clusters = algorithm.fit_predict(X_scaled)\n",
    "    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=mglearn.cm3, s=60)\n",
    "    ax.set_title(\"{} - ARI: {:.2f}\".format(algorithm.__class__.__name__, adjusted_rand_score(y, clusters)))\n",
    "\n",
    "Сравнение на различните видове клъстеризация\n",
    "\n",
    "В документацията на модула sklearn има много добро визуално сравнение на резултатите от различните видове клъстеризация при различни форми на клъстерите, както и обяснение в кои случаи кой алгоритъм е най-подходящ.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods\n",
    "Въпроси?\n",
    "\n",
    " \n",
    "\n",
    "2. Намаляване на размерността\n",
    "Principal Component Analysis\n",
    "\n",
    "    Или накратко, PCA\n",
    "    Опитва се да намали броя измерения на характеристиките.\n",
    "    Завърта данните по начин, в който да намери по-малкомерен линеен базис, който да запазва повечето информация.\n",
    "\n",
    "    Повече информация - в документацията.\n",
    "\n",
    "mglearn.plots.plot_pca_illustration()\n",
    "\n",
    "Бихме могли да го ползваме за визуализация.\n",
    "\n",
    "Да се опитаме да го приложим върху cancer. Първо, нека да видим какви характеристики има:\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "fig, axes = plt.subplots(15, 2, figsize=(10, 20))\n",
    "malignant = cancer.data[cancer.target == 0]\n",
    "benign = cancer.data[cancer.target == 1]\n",
    "\n",
    "ax = axes.ravel()\n",
    "\n",
    "for i in range(30):\n",
    "    _, bins = np.histogram(cancer.data[:, i], bins=50)\n",
    "    ax[i].hist(malignant[:, i], bins=bins, color=mglearn.cm3(0), alpha=.5)\n",
    "    ax[i].hist(benign[:, i], bins=bins, color=mglearn.cm3(2), alpha=.5)\n",
    "    ax[i].set_title(cancer.feature_names[i])\n",
    "    ax[i].set_yticks(())\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "cancer.data.shape\n",
    "\n",
    "(569, 30)\n",
    "\n",
    "Преди да го прекараме през PCA е добре да мине през StandardScaler:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(cancer.data)\n",
    "X_scaled = scaler.transform(cancer.data)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "X_pca = pca.transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "mglearn.discrete_scatter(X_pca[:, 0], X_pca[:, 1], cancer.target)\n",
    "plt.legend(cancer.target_names, loc='best')\n",
    "plt.gca().set_aspect('equal');\n",
    "\n",
    "pca.components_\n",
    "\n",
    "array([[ 0.21890244,  0.10372458,  0.22753729,  0.22099499,  0.14258969,\n",
    "         0.23928535,  0.25840048,  0.26085376,  0.13816696,  0.06436335,\n",
    "         0.20597878,  0.01742803,  0.21132592,  0.20286964,  0.01453145,\n",
    "         0.17039345,  0.15358979,  0.1834174 ,  0.04249842,  0.10256832,\n",
    "         0.22799663,  0.10446933,  0.23663968,  0.22487053,  0.12795256,\n",
    "         0.21009588,  0.22876753,  0.25088597,  0.12290456,  0.13178394],\n",
    "       [-0.23385713, -0.05970609, -0.21518136, -0.23107671,  0.18611302,\n",
    "         0.15189161,  0.06016536, -0.0347675 ,  0.19034877,  0.36657547,\n",
    "        -0.10555215,  0.08997968, -0.08945723, -0.15229263,  0.20443045,\n",
    "         0.2327159 ,  0.19720728,  0.13032156,  0.183848  ,  0.28009203,\n",
    "        -0.21986638, -0.0454673 , -0.19987843, -0.21935186,  0.17230435,\n",
    "         0.14359317,  0.09796411, -0.00825724,  0.14188335,  0.27533947]])\n",
    "\n",
    "plt.matshow(pca.components_, cmap='viridis')\n",
    "plt.yticks([0, 1], [\"First component\", \"Second component\"])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(cancer.feature_names)), cancer.feature_names, rotation=60, ha='left')\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Principal components\");\n",
    "\n",
    "Как броят компоненти влияе на представянето на алгоритъма?\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), LinearSVC(C=0.01))\n",
    "\n",
    "cross_val_score(pipeline, X, y).mean()\n",
    "\n",
    "0.9789163173420278\n",
    "\n",
    "for i in range(1, 10):\n",
    "    pipeline = make_pipeline(StandardScaler(), PCA(n_components=i), LinearSVC(C=0.01))\n",
    "    score = cross_val_score(pipeline, X, y).mean()\n",
    "    print(\"Score for {} components: {}\".format(i, score))\n",
    "\n",
    "Score for 1 components: 0.9139264089427108\n",
    "Score for 2 components: 0.9508461419034312\n",
    "Score for 3 components: 0.9455519329296692\n",
    "Score for 4 components: 0.9666511411271541\n",
    "Score for 5 components: 0.968390001552554\n",
    "Score for 6 components: 0.9719142990218911\n",
    "Score for 7 components: 0.9701443875174662\n",
    "Score for 8 components: 0.9824406148113647\n",
    "Score for 9 components: 0.9806862288464524\n",
    "\n",
    "Допълнително: Non-negative matrix factorization\n",
    "\n",
    "Друг алгоритъм, полезен за декомпозиране:\n",
    "\n",
    "    Работи само с позитивни числа.\n",
    "    Подходящ където резултатите са сбор от независими променливи (напр. много хора говорещи в една стая).\n",
    "    Понякога се интерпретира по-лесно от PCA.\n",
    "\n",
    "Повече информация в документацията.\n",
    "\n",
    "mglearn.plots.plot_nmf_illustration()\n",
    "\n",
    "Пример\n",
    "\n",
    "Декомпозиране на сигнал.\n",
    "\n",
    "    Имате трима човека, говорещи едновременно в една стая.\n",
    "    Има n микрофона из стаята, които записват всичко.\n",
    "    Всеки е на различно място и записва източниците с различна сила.\n",
    "\n",
    "Може да ползваме NMF да извлечем оригиналните сигнали.\n",
    "\n",
    "Да генерираме три сигнала:\n",
    "\n",
    "S = mglearn.datasets.make_signals()\n",
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(S, '-')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Signal\");\n",
    "S.shape\n",
    "\n",
    "(2000, 3)\n",
    "\n",
    "Сега ще ги прекараме през 100 микрофона, всеки от които на произволна дистанция от всеки човек:\n",
    "\n",
    "m = np.random.RandomState(0).uniform(size=(100, 3))\n",
    "print(m.shape)\n",
    "m[:5]\n",
    "\n",
    "(100, 3)\n",
    "\n",
    "array([[0.5488135 , 0.71518937, 0.60276338],\n",
    "       [0.54488318, 0.4236548 , 0.64589411],\n",
    "       [0.43758721, 0.891773  , 0.96366276],\n",
    "       [0.38344152, 0.79172504, 0.52889492],\n",
    "       [0.56804456, 0.92559664, 0.07103606]])\n",
    "\n",
    "Това е матрица, където редовете са микрофони, а колоните са дистанцията от всеки микрофон.\n",
    "\n",
    "Извеждаме 100 записа:\n",
    "\n",
    "X = np.dot(S, m.T)\n",
    "X.shape\n",
    "\n",
    "(2000, 100)\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(X[:, :3], '-');\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=3, random_state=42)\n",
    "nmf.fit_transform(X).shape\n",
    "\n",
    "(2000, 3)\n",
    "\n",
    "nmf = NMF(n_components=3, random_state=42)\n",
    "S_ = nmf.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "H = pca.fit_transform(X)\n",
    "\n",
    "models = [S, S_, H]\n",
    "names = ['True sources',\n",
    "         'NMF recovered signals',\n",
    "         'PCA recovered signals']\n",
    "fig, axes = plt.subplots(3, figsize=(12, 8), gridspec_kw={'hspace': .5}, subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "for model, name, ax in zip(models, names, axes):\n",
    "    ax.set_title(name)\n",
    "    ax.plot(model[:, :3], '-')\n",
    "\n",
    "Визуализация в клъстерите на digits\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5), subplot_kw={'xticks':(), 'yticks': ()})\n",
    "\n",
    "for ax, img in zip(axes.ravel(), digits.images):\n",
    "    ax.imshow(img)\n",
    "\n",
    "Може да пробваме с PCA:\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(digits.data)\n",
    "\n",
    "digits_pca = pca.transform(digits.data)\n",
    "colors = [\"#476A2A\", \"#7851B8\", \"#BD3430\", \"#4A2D4E\", \"#875525\", \"#A83683\", \"#4E655E\", \"#853541\", \"#3A3120\", \"#535D8E\"]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(digits_pca[:, 0].min(), digits_pca[:, 0].max())\n",
    "plt.ylim(digits_pca[:, 1].min(), digits_pca[:, 1].max())\n",
    "\n",
    "for i in range(len(digits.data)):\n",
    "    plt.text(digits_pca[i, 0], digits_pca[i, 1], str(digits.target[i]), color=colors[digits.target[i]], fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "Въпреки, че има забележими клъстери от някои числа, PCA не се справя идеално.\n",
    "\n",
    "Може да пробваме и един друг метод, в който няма да навлизаме - TSNE.\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(random_state=0)\n",
    "\n",
    "digits_tsne = tsne.fit_transform(digits.data)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(digits_tsne[:, 0].min(), digits_tsne[:, 0].max() + 1)\n",
    "plt.ylim(digits_tsne[:, 1].min(), digits_tsne[:, 1].max() + 1)\n",
    "\n",
    "for i in range(len(digits.data)):\n",
    "    plt.text(digits_tsne[i, 0], digits_tsne[i, 1], str(digits.target[i]), color=colors[digits.target[i]], fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "Въпроси?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
